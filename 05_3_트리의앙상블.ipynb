{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 05-3 트리의 앙상블\n",
        "앙상블 학습이 무엇인지 이해하고 다양한 앙상블 학습 알고리즘을 실습을 통해 배운다."
      ],
      "metadata": {
        "id": "iphc91W-vs56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정형 데이터와 비정형 데이터\n",
        "- 정형 데이터 : 정해진 형식과 구조에 따라 저장된 데이터\n",
        "- 비정형 데이터 : 텍스트 데이터, 사진, 음악 등\n",
        "\n",
        "\n",
        "**정형 데이터**에는 머신러닝 알고리즘이 잘 맞음. 그중에 정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 것이 앙상블 학습이다.\n",
        "\n",
        "참고로 **비정형 데이터**에는 신경망 알고리즘이 좋음. 왜냐면 비정형 데이터는 규칙성을 찾기 어려워 전통적인 머신러닝 방법으로는 모델을 만들기 까다롭다."
      ],
      "metadata": {
        "id": "fQU2xa_EvzJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤포레스트\n",
        "- 부트스트랩 샘플 사용. 앙상블 학습의 대표 주자 중 하나로 안정적인 성능 덕분에 널리 사용되고 있음\n",
        "- 결정 트리를 랜덤하게 만들어 결정 트리의 숲을 만든다. 그리고 각 결정 트리의 예측을 사용해 최종 예측을 만든다.\n",
        "\n",
        "랜덤포레스트는 랜덤하게 선택한 샘플과 특성을 사용하기 때문에 훈련 세트에 과대적합되는 것을 막아주고, 검증 세트와 테스트 세트에서 안정적인 성능을 얻을 수 있다.\n",
        "\n",
        "여기서 '**부트스트랩 방식**'이란 데이터 세트에서 중복을 허용하여 데이터를 샘플링하는 방식을 뜻한다."
      ],
      "metadata": {
        "id": "twD02io7RzZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "train_input, test_input, train_target, test_target = train_test_split(\n",
        "    data, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UTefVMvOR0Mm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "# 기본적으로 100개의 결정 트리 사용\n",
        "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "# return_train_score 매개변수가 True면, 검증 점수뿐만 아니라 훈련 세트에 대한 점수도 같이 반환됨\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQFKHY0lR0H-",
        "outputId": "59504a57-7817-43e4-acac-c802bf2834a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9973541965122431 0.8905151032797809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(train_input, train_target)\n",
        "\n",
        "print(rf.feature_importances_)\n",
        "# 결정 트리에서의 특성 중요도와 차이가 있음\n",
        "# 랜덤 포레스트가 특성의 일부를 랜덤하게 선택하여 결정 트리를 훈련하기 때문\n",
        "# 하나의 특성에 과도하게 집중하지 않고, 좀 더 많은 특성이 훈련에 기여할 기회를 얻는다 → 과대적합 줄이고, 일반화 성능 높이는데 도움"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sigb3S8WR0DW",
        "outputId": "f0c75c5b-eeb9-4bbb-ea95-454026465861"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier에서는 자체적으로 모델을 평가하는 점수를 얻을 수 있음\n",
        "# OOB 점수를 사용하면 교차 검증을 대신할 수 있어서 결과적으로 훈련 세트에 더 많은 샘플을 사용할 수 있음\n",
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "rf.fit(train_input, train_target)\n",
        "\n",
        "print(rf.oob_score_)"
      ],
      "metadata": {
        "id": "IwLzrzHhR0BF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188e1e4f-d5ab-44bc-c2ae-6300658f9cd3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 엑스트라 트리\n",
        "엑스트라 트리는 랜덤 포레스트와 비슷하게 결정 트리를 사용하여 앙상블 모델을 만들지만 부트스트랩 샘플을 사용하지 않음. 대신 랜덤하게 노드를 분할해 과대적합을 감소시킨다.\n",
        "\n",
        "랜덤하게 노드를 분할하기 때문에 빠른 계산 속도가 엑스트라 트리의 장점"
      ],
      "metadata": {
        "id": "6TEeuv9AXP1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZepkwWiwRz-m",
        "outputId": "07f28528-0ee5-4f8f-99eb-85478ec4a3ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9974503966084433 0.8887848893166506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "et.fit(train_input, train_target)\n",
        "\n",
        "print(et.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQdb6rjeRz8G",
        "outputId": "26441a56-69e9-4fa5-fba6-9ad4eee2f621"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그레이디언트 부스팅\n",
        "- 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블 하는 방법\n",
        "- 랜덤 포레스트나 엑스트라 트리와 달리 결정 트리를 연속적으로 추가하여 손실 함수를 최소화하는 앙상블 방법. 이런 이유로 훈련 속도가 조금 느리지만 더 좋은 성능을 기대할 수 있음"
      ],
      "metadata": {
        "id": "RpoZztzkYVOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFMcblROYU9O",
        "outputId": "17a5637a-f1c6-4b61-da95-d1756838d1d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "# 학습률을 증가시키고 트리의 개수를 늘리면 조금 더 성능이 향상될 수 있음\n",
        "# learning_rate : 학습률, 트리가 앙상블에 기여하는 정도(기본값 0.1)\n",
        "# n_estimators : 결정 트리 개수(기본값 100)\n",
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(\"time :\", time.time() - start)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJIAYoirRz52",
        "outputId": "089049ee-cbee-4b83-fd86-35f554143456"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time : 9.986716747283936\n",
            "0.9464595437171814 0.8780082549788999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arNGUnEPRz3m",
        "outputId": "5910f291-e7cd-46a6-e2fd-d990e457fdbb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.15872278 0.68010884 0.16116839]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 히스토그램 기반 그레이디언트 부스팅\n",
        "가장 뛰어난 앙상블 학습으로 평가받는다.\n",
        "\n",
        "히스토그램 기반 그레이디언트 부스팅은 훈련 데이터를 256개의 구간으로 변환하여 사용하기 때문에 노드 분할 속도가 매우 빠름"
      ],
      "metadata": {
        "id": "9A0o5azEcdUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, train_input, train_target, return_train_score=True)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhLhiFReRz1G",
        "outputId": "26e19223-047b-4caf-a7a8-fafc00068771"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  \"Since version 1.0, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "hgb.fit(train_input, train_target)\n",
        "result = permutation_importance(hgb, train_input, train_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeSgmFkERzy-",
        "outputId": "11991151-3f04-4ae8-ef12-b669d2c2d2ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08876275 0.23438522 0.08027708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wa1pV2kGDF0",
        "outputId": "58514234-e2ad-4fec-c77f-ceed8ddfc15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05969231 0.20238462 0.049     ]\n"
          ]
        }
      ],
      "source": [
        "result = permutation_importance(hgb, test_input, test_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "\n",
        "print(result.importances_mean)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hgb.score(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d-zKBEUXQsm",
        "outputId": "38b5e159-d8e6-4ea3-e43a-fd27b5b07167"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **XGBoost** 라이브러리에서의 히스토그램 기반 그레이디언트 부스팅 알고리즘 구현"
      ],
      "metadata": {
        "id": "9sf4ZAJoeIsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
        "scores = cross_validate(xgb, train_input, train_target, return_train_score=True)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQMP76-zXQoW",
        "outputId": "6a694928-3fa5-4504-ce04-bdbddd1abf0e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8824322471423747 0.8726214185237284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LightGBM** 라이브러리에서의 히스토그램 기반 그레이디언트 부스팅 알고리즘 구현"
      ],
      "metadata": {
        "id": "l0PtpJn3e9ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9nzPh7iXQl_",
        "outputId": "04c52467-c0df-4563-e8f5-8d78d463e54c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9338079582727165 0.8789710890649293\n"
          ]
        }
      ]
    }
  ]
}